{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PyTorch SimCLR Notebook.ipynb","provenance":[{"file_id":"1ObAYvVKQjMG5nd2wIno7j2y_X91E9IrX","timestamp":1622646769475}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f63bfd608ca14f14951a4b487a2a6153":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2e89e91bead34b75ba73e064652732f2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6ae573c5bc58480ab674bf0a0cb7309c","IPY_MODEL_17a1c60c462d4078ae17d4087e6ad448"]}},"2e89e91bead34b75ba73e064652732f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6ae573c5bc58480ab674bf0a0cb7309c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_31f80f9d36b947939d15e351b22e35c9","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":170498071,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":170498071,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_850c5f635987417491d8737d64d813af"}},"17a1c60c462d4078ae17d4087e6ad448":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c37d10065b2d457e8a45267377ea62d6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170499072/? [00:29&lt;00:00, 5856988.77it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_85fdbd1f3e8746fdb579957a5e53592b"}},"31f80f9d36b947939d15e351b22e35c9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"850c5f635987417491d8737d64d813af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c37d10065b2d457e8a45267377ea62d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"85fdbd1f3e8746fdb579957a5e53592b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"jF8ZoVrwt0n0"},"source":["# SimCLR\n","PyTorch implementation of SimCLR: A Simple Framework for Contrastive Learning of Visual Representations by T. Chen et al. With support for the LARS (Layer-wise Adaptive Rate Scaling) optimizer and global batch norm.\n","\n","[Link to paper](https://arxiv.org/pdf/2002.05709.pdf)\n"]},{"cell_type":"markdown","metadata":{"id":"Lt6WMxjCvN3o"},"source":["## Setup the repository"]},{"cell_type":"code","metadata":{"id":"53JMIYtat8tT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622657911455,"user_tz":240,"elapsed":8160,"user":{"displayName":"Rohit Jagga","photoUrl":"","userId":"14887061695205225708"}},"outputId":"825f4a06-8cdd-4da2-809a-0c9426cccb1e"},"source":["!git clone https://github.com/spijkervet/SimCLR.git\n","%cd SimCLR\n","!mkdir -p logs && cd logs && wget https://github.com/Spijkervet/SimCLR/releases/download/1.2/checkpoint_100.tar && cd ../\n","!sh setup.sh || python3 -m pip install -r requirements.txt || exit 1\n","!pip install  pyyaml --upgrade"],"execution_count":44,"outputs":[{"output_type":"stream","text":["Cloning into 'SimCLR'...\n","remote: Enumerating objects: 528, done.\u001b[K\n","remote: Counting objects: 100% (1/1), done.\u001b[K\n","remote: Total 528 (delta 0), reused 0 (delta 0), pack-reused 527\u001b[K\n","Receiving objects: 100% (528/528), 325.14 KiB | 20.32 MiB/s, done.\n","Resolving deltas: 100% (292/292), done.\n","/content/SimCLR/SimCLR\n","--2021-06-02 18:18:24--  https://github.com/Spijkervet/SimCLR/releases/download/1.2/checkpoint_100.tar\n","Resolving github.com (github.com)... 140.82.112.3\n","Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://github-releases.githubusercontent.com/246276098/8ae3c180-64bd-11ea-91fe-0f47017fe9be?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210602%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210602T181824Z&X-Amz-Expires=300&X-Amz-Signature=78c8e4ead917c352ed3be29713df3a8d1a02f6833ddf0fb6f0588caebb110b6f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=246276098&response-content-disposition=attachment%3B%20filename%3Dcheckpoint_100.tar&response-content-type=application%2Foctet-stream [following]\n","--2021-06-02 18:18:24--  https://github-releases.githubusercontent.com/246276098/8ae3c180-64bd-11ea-91fe-0f47017fe9be?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210602%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210602T181824Z&X-Amz-Expires=300&X-Amz-Signature=78c8e4ead917c352ed3be29713df3a8d1a02f6833ddf0fb6f0588caebb110b6f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=246276098&response-content-disposition=attachment%3B%20filename%3Dcheckpoint_100.tar&response-content-type=application%2Foctet-stream\n","Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n","Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 111607632 (106M) [application/octet-stream]\n","Saving to: ‘checkpoint_100.tar’\n","\n","checkpoint_100.tar  100%[===================>] 106.44M  67.8MB/s    in 1.6s    \n","\n","2021-06-02 18:18:25 (67.8 MB/s) - ‘checkpoint_100.tar’ saved [111607632/111607632]\n","\n","setup.sh: 2: setup.sh: conda: not found\n","setup.sh: 2: setup.sh: conda: not found\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.8.1+cu101)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.9.1+cu101)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (5.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 1)) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 1)) (3.7.4.3)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->-r requirements.txt (line 2)) (7.1.2)\n","Requirement already up-to-date: pyyaml in /usr/local/lib/python3.7/dist-packages (5.4.1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fQ3jq3cWynLf"},"source":["# Part 1:\n","## SimCLR pre-training"]},{"cell_type":"code","metadata":{"id":"0jhAv3hv8IHn","executionInfo":{"status":"ok","timestamp":1622657961321,"user_tz":240,"elapsed":142,"user":{"displayName":"Rohit Jagga","photoUrl":"","userId":"14887061695205225708"}}},"source":["# whether to use a TPU or not (set in Runtime -> Change Runtime Type)\n","use_tpu = False"],"execution_count":45,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bwW10d2O7pn8"},"source":["#### Install PyTorch/XLA"]},{"cell_type":"code","metadata":{"id":"Vj84aiC27oxS","executionInfo":{"status":"ok","timestamp":1622657964269,"user_tz":240,"elapsed":131,"user":{"displayName":"Rohit Jagga","photoUrl":"","userId":"14887061695205225708"}}},"source":["if use_tpu:\n","  VERSION = \"20200220\" #@param [\"20200220\",\"nightly\", \"xrt==1.15.0\"]\n","  !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n","  !python pytorch-xla-env-setup.py --version $VERSION"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"oNDRcPbbymlX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622657965072,"user_tz":240,"elapsed":101,"user":{"displayName":"Rohit Jagga","photoUrl":"","userId":"14887061695205225708"}},"outputId":"443e7b72-fa3b-48a9-c284-3a69279f3032"},"source":["import os\n","import torch\n","import numpy as np\n","\n","if use_tpu:\n","  # imports the torch_xla package for TPU support\n","  import torch_xla\n","  import torch_xla.core.xla_model as xm\n","  dev = xm.xla_device()\n","  print(dev)\n","  \n","import torchvision\n","import argparse\n","\n","from torch.utils.tensorboard import SummaryWriter\n","\n","apex = False\n","try:\n","    from apex import amp\n","    apex = True\n","except ImportError:\n","    print(\n","        \"Install the apex package from https://www.github.com/nvidia/apex to use fp16 for training\"\n","    )\n","\n","from model import save_model, load_optimizer\n","from simclr import SimCLR\n","from simclr.modules import get_resnet, NT_Xent\n","from simclr.modules.transformations import TransformsSimCLR"],"execution_count":47,"outputs":[{"output_type":"stream","text":["Install the apex package from https://www.github.com/nvidia/apex to use fp16 for training\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eYbV0fa_y03Z"},"source":["### Load arguments from `config/config.yaml`"]},{"cell_type":"code","metadata":{"id":"1klUf-IuyxdL","executionInfo":{"status":"ok","timestamp":1622657977270,"user_tz":240,"elapsed":103,"user":{"displayName":"Rohit Jagga","photoUrl":"","userId":"14887061695205225708"}}},"source":["from pprint import pprint\n","import argparse\n","from utils import yaml_config_hook\n","\n","parser = argparse.ArgumentParser(description=\"SimCLR\")\n","config = yaml_config_hook(\"./config/config.yaml\")\n","for k, v in config.items():\n","    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n","\n","args = parser.parse_args([])\n","args.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"O86__UhA0Lvr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622657983942,"user_tz":240,"elapsed":102,"user":{"displayName":"Rohit Jagga","photoUrl":"","userId":"14887061695205225708"}},"outputId":"e2af52d1-8efd-468b-8c46-2cdb4b388bd0"},"source":["### override any configuration parameters here, e.g. to adjust for use on GPUs on the Colab platform:\n","args.batch_size = 128\n","args.resnet = \"resnet18\"\n","pprint(vars(args))"],"execution_count":49,"outputs":[{"output_type":"stream","text":["{'batch_size': 128,\n"," 'dataparallel': 0,\n"," 'dataset': 'CIFAR10',\n"," 'dataset_dir': './datasets',\n"," 'device': device(type='cuda'),\n"," 'epoch_num': 100,\n"," 'epochs': 100,\n"," 'gpus': 1,\n"," 'image_size': 224,\n"," 'logistic_batch_size': 256,\n"," 'logistic_epochs': 500,\n"," 'model_path': 'save',\n"," 'nodes': 1,\n"," 'nr': 0,\n"," 'optimizer': 'Adam',\n"," 'pretrain': True,\n"," 'projection_dim': 64,\n"," 'reload': False,\n"," 'resnet': 'resnet18',\n"," 'seed': 42,\n"," 'start_epoch': 0,\n"," 'temperature': 0.5,\n"," 'weight_decay': 1e-06,\n"," 'workers': 8}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xJfeOM9PzNoF"},"source":["### Load dataset into train loader"]},{"cell_type":"code","metadata":{"id":"YGcskdBsytbj","colab":{"base_uri":"https://localhost:8080/","height":154,"referenced_widgets":["f63bfd608ca14f14951a4b487a2a6153","2e89e91bead34b75ba73e064652732f2","6ae573c5bc58480ab674bf0a0cb7309c","17a1c60c462d4078ae17d4087e6ad448","31f80f9d36b947939d15e351b22e35c9","850c5f635987417491d8737d64d813af","c37d10065b2d457e8a45267377ea62d6","85fdbd1f3e8746fdb579957a5e53592b"]},"executionInfo":{"status":"ok","timestamp":1622655118901,"user_tz":240,"elapsed":5772,"user":{"displayName":"Rohit Jagga","photoUrl":"","userId":"14887061695205225708"}},"outputId":"51835314-9dbb-4c9f-9657-28e200d02376"},"source":["torch.manual_seed(args.seed)\n","np.random.seed(args.seed)\n","\n","if args.dataset == \"STL10\":\n","    train_dataset = torchvision.datasets.STL10(\n","        args.dataset_dir,\n","        split=\"unlabeled\",\n","        download=True,\n","        transform=TransformsSimCLR(size=args.image_size),\n","    )\n","elif args.dataset == \"CIFAR10\":\n","    train_dataset = torchvision.datasets.CIFAR10(\n","        args.dataset_dir,\n","        download=True,\n","        transform=TransformsSimCLR(size=args.image_size),\n","    )\n","else:\n","    raise NotImplementedError\n","\n","if args.nodes > 1:\n","    train_sampler = torch.utils.data.distributed.DistributedSampler(\n","        train_dataset, num_replicas=args.world_size, rank=rank, shuffle=True\n","    )\n","else:\n","    train_sampler = None\n","\n","train_loader = torch.utils.data.DataLoader(\n","    train_dataset,\n","    batch_size=args.batch_size,\n","    shuffle=(train_sampler is None),\n","    drop_last=True,\n","    num_workers=args.workers,\n","    sampler=train_sampler,\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./datasets/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f63bfd608ca14f14951a4b487a2a6153","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./datasets/cifar-10-python.tar.gz to ./datasets\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"RBlXZwvjzPmp"},"source":["### Load the SimCLR model, optimizer and learning rate scheduler"]},{"cell_type":"code","metadata":{"id":"xERq_yHSzJRX"},"source":["# initialize ResNet\n","encoder = get_resnet(args.resnet, pretrained=False)\n","n_features = encoder.fc.in_features  # get dimensions of fc layer\n","\n","# initialize model\n","model = SimCLR(encoder, args.projection_dim, n_features)\n","if args.reload:\n","    model_fp = os.path.join(\n","        args.model_path, \"checkpoint_{}.tar\".format(args.epoch_num)\n","    )\n","    model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n","model = model.to(args.device)\n","\n","# optimizer / loss\n","optimizer, scheduler = load_optimizer(args, model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dtNCVEynzjtV"},"source":["### Initialize the criterion (NT-Xent loss)"]},{"cell_type":"code","metadata":{"id":"u067AY93zh-k"},"source":["criterion = NT_Xent(args.batch_size, args.temperature, world_size=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RyJ3ulWqzViL"},"source":["### Setup TensorBoard for logging experiments"]},{"cell_type":"code","metadata":{"id":"zZNieMqfzU7H"},"source":["writer = SummaryWriter()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yXMOVfg47Hlh"},"source":["### Train function"]},{"cell_type":"code","metadata":{"id":"KyMFhpB-7HGj"},"source":["def train(args, train_loader, model, criterion, optimizer, writer):\n","    loss_epoch = 0\n","    for step, ((x_i, x_j), _) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        x_i = x_i.cuda(non_blocking=True)\n","        x_j = x_j.cuda(non_blocking=True)\n","\n","        # positive pair, with encoding\n","        h_i, h_j, z_i, z_j = model(x_i, x_j)\n","\n","        loss = criterion(z_i, z_j)\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        if step % 50 == 0:\n","            print(f\"Step [{step}/{len(train_loader)}]\\t Loss: {loss.item()}\")\n","\n","        writer.add_scalar(\"Loss/train_epoch\", loss.item(), args.global_step)\n","        loss_epoch += loss.item()\n","        args.global_step += 1\n","    return loss_epoch\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cN5KBK-yztGD"},"source":["### Start training"]},{"cell_type":"code","metadata":{"id":"TdCrD62hzjDQ","colab":{"base_uri":"https://localhost:8080/","height":565},"executionInfo":{"status":"error","timestamp":1622655631234,"user_tz":240,"elapsed":484618,"user":{"displayName":"Rohit Jagga","photoUrl":"","userId":"14887061695205225708"}},"outputId":"ee9d92fb-f3bf-4368-c5c5-3b05c8f20347"},"source":["args.global_step = 0\n","args.current_epoch = 0\n","for epoch in range(args.start_epoch, args.epochs):\n","    lr = optimizer.param_groups[0][\"lr\"]\n","    loss_epoch = train(args, train_loader, model, criterion, optimizer, writer)\n","\n","    if scheduler:\n","        scheduler.step()\n","\n","    # save every 10 epochs\n","    if epoch % 10 == 0:\n","        save_model(args, model, optimizer)\n","\n","    writer.add_scalar(\"Loss/train\", loss_epoch / len(train_loader), epoch)\n","    writer.add_scalar(\"Misc/learning_rate\", lr, epoch)\n","    print(\n","        f\"Epoch [{epoch}/{args.epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t lr: {round(lr, 5)}\"\n","    )\n","    args.current_epoch += 1\n","\n","# end training\n","save_model(args, model, optimizer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["Step [0/390]\t Loss: 5.5370635986328125\n","Step [50/390]\t Loss: 5.313588619232178\n","Step [100/390]\t Loss: 5.321504592895508\n","Step [150/390]\t Loss: 5.199620723724365\n","Step [200/390]\t Loss: 5.18595552444458\n","Step [250/390]\t Loss: 5.118190765380859\n","Step [300/390]\t Loss: 5.041810989379883\n","Step [350/390]\t Loss: 5.033085346221924\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-f75b52b629a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# save every 10 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loss/train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_epoch\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/SimCLR/model.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(args, model, optimizer)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'save/checkpoint_0.tar'"]}]},{"cell_type":"markdown","metadata":{"id":"77BXUR9_4hNc"},"source":["## OPTIONAL: Download last checkpoint to local drive (replace `100` with `args.epochs`)"]},{"cell_type":"code","metadata":{"id":"d7eHATk04Sgu","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1622655827144,"user_tz":240,"elapsed":115,"user":{"displayName":"Rohit Jagga","photoUrl":"","userId":"14887061695205225708"}},"outputId":"f2baca52-68f8-47ee-cfa0-ee53a7ef2fd5"},"source":["from google.colab import files\n","files.download('checkpoint_100.tar')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_ddeb7cf5-a72a-46f2-a1e3-adedea150ee1\", \"checkpoint_100.tar\", 111607632)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"tAQpjiuJy61N"},"source":["# Part 2:\n","## Linear evaluation using logistic regression, using weights from frozen, pre-trained SimCLR model"]},{"cell_type":"markdown","metadata":{"id":"24wrzMP2vYcV"},"source":[""]},{"cell_type":"code","metadata":{"id":"kFyS9RvpuCuC","executionInfo":{"status":"ok","timestamp":1622658033836,"user_tz":240,"elapsed":107,"user":{"displayName":"Rohit Jagga","photoUrl":"","userId":"14887061695205225708"}}},"source":["import torch\n","import torchvision\n","import numpy as np\n","import argparse\n","#from modules import LogisticRegression\n"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"id":"pZRtPBCLvgqz","executionInfo":{"status":"ok","timestamp":1622658037174,"user_tz":240,"elapsed":109,"user":{"displayName":"Rohit Jagga","photoUrl":"","userId":"14887061695205225708"}}},"source":["def train(args, loader, simclr_model, model, criterion, optimizer):\n","    loss_epoch = 0\n","    accuracy_epoch = 0\n","    for step, (x, y) in enumerate(loader):\n","        optimizer.zero_grad()\n","\n","        x = x.to(args.device)\n","        y = y.to(args.device)\n","\n","        output = model(x)\n","        loss = criterion(output, y)\n","\n","        predicted = output.argmax(1)\n","        acc = (predicted == y).sum().item() / y.size(0)\n","        accuracy_epoch += acc\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        loss_epoch += loss.item()\n","        # if step % 100 == 0:\n","        #     print(\n","        #         f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()}\\t Accuracy: {acc}\"\n","        #     )\n","\n","    return loss_epoch, accuracy_epoch"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"id":"skBYAPb2uKB5","executionInfo":{"status":"ok","timestamp":1622658050564,"user_tz":240,"elapsed":115,"user":{"displayName":"Rohit Jagga","photoUrl":"","userId":"14887061695205225708"}}},"source":["def test(args, loader, simclr_model, model, criterion, optimizer):\n","    loss_epoch = 0\n","    accuracy_epoch = 0\n","    model.eval()\n","    for step, (x, y) in enumerate(loader):\n","        model.zero_grad()\n","\n","        x = x.to(args.device)\n","        y = y.to(args.device)\n","\n","        output = model(x)\n","        loss = criterion(output, y)\n","\n","        predicted = output.argmax(1)\n","        acc = (predicted == y).sum().item() / y.size(0)\n","        accuracy_epoch += acc\n","\n","        loss_epoch += loss.item()\n","\n","    return loss_epoch, accuracy_epoch\n","\n"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"OJk4-nc-vkF0","executionInfo":{"status":"ok","timestamp":1622658056346,"user_tz":240,"elapsed":106,"user":{"displayName":"Rohit Jagga","photoUrl":"","userId":"14887061695205225708"}}},"source":["from pprint import pprint\n","from utils import yaml_config_hook\n","\n","parser = argparse.ArgumentParser(description=\"SimCLR\")\n","config = yaml_config_hook(\"./config/config.yaml\")\n","for k, v in config.items():\n","    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n","\n","args = parser.parse_args([])\n","\n","if use_tpu:\n","  args.device = dev\n","else:\n","  args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":57,"outputs":[]},{"cell_type":"code","metadata":{"id":"_7cSwhu55KJc","executionInfo":{"status":"ok","timestamp":1622659295446,"user_tz":240,"elapsed":117,"user":{"displayName":"Rohit Jagga","photoUrl":"","userId":"14887061695205225708"}}},"source":["args.batch_size = 64\n","args.dataset = \"CIFAR10\" # make sure to check this with the (pre-)trained checkpoint\n","args.resnet = \"resnet50\" # make sure to check this with the (pre-)trained checkpoint\n","args.model_path = \"logs\"\n","args.epoch_num = 100\n","args.logistic_epochs = 500"],"execution_count":71,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hTgCE-mZ7ygx"},"source":["### Download a pre-trained model for demonstration purposes"]},{"cell_type":"code","metadata":{"id":"WMuPgP3h7vfi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622658653449,"user_tz":240,"elapsed":1601,"user":{"displayName":"Rohit Jagga","photoUrl":"","userId":"14887061695205225708"}},"outputId":"155cae92-170e-4f58-dd1b-6af4247e686a"},"source":["!wget https://github.com/Spijkervet/SimCLR/releases/download/1.2/checkpoint_100.tar"],"execution_count":66,"outputs":[{"output_type":"stream","text":["--2021-06-02 18:30:51--  https://github.com/Spijkervet/SimCLR/releases/download/1.2/checkpoint_100.tar\n","Resolving github.com (github.com)... 140.82.114.4\n","Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://github-releases.githubusercontent.com/246276098/8ae3c180-64bd-11ea-91fe-0f47017fe9be?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210602%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210602T183052Z&X-Amz-Expires=300&X-Amz-Signature=32c85b199001727fc49bbcdc9491eaa50b9a39d352ba612b68ea55be9351f81c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=246276098&response-content-disposition=attachment%3B%20filename%3Dcheckpoint_100.tar&response-content-type=application%2Foctet-stream [following]\n","--2021-06-02 18:30:52--  https://github-releases.githubusercontent.com/246276098/8ae3c180-64bd-11ea-91fe-0f47017fe9be?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210602%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210602T183052Z&X-Amz-Expires=300&X-Amz-Signature=32c85b199001727fc49bbcdc9491eaa50b9a39d352ba612b68ea55be9351f81c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=246276098&response-content-disposition=attachment%3B%20filename%3Dcheckpoint_100.tar&response-content-type=application%2Foctet-stream\n","Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.111.154, 185.199.108.154, 185.199.109.154, ...\n","Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.111.154|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 111607632 (106M) [application/octet-stream]\n","Saving to: ‘checkpoint_100.tar.1’\n","\n","checkpoint_100.tar. 100%[===================>] 106.44M   105MB/s    in 1.0s    \n","\n","2021-06-02 18:30:53 (105 MB/s) - ‘checkpoint_100.tar.1’ saved [111607632/111607632]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GWRuVrZZ5Vm1"},"source":["### Load dataset into train/test dataloaders"]},{"cell_type":"code","metadata":{"id":"iPGuFjLW5PF9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622659311180,"user_tz":240,"elapsed":1712,"user":{"displayName":"Rohit Jagga","photoUrl":"","userId":"14887061695205225708"}},"outputId":"4c811ddb-bfeb-4877-d943-a91717c79b99"},"source":["if args.dataset == \"STL10\":\n","    train_dataset = torchvision.datasets.STL10(\n","        args.dataset_dir,\n","        split=\"train\",\n","        download=True,\n","        transform=TransformsSimCLR(size=args.image_size).test_transform,\n","    )\n","    test_dataset = torchvision.datasets.STL10(\n","        args.dataset_dir,\n","        split=\"test\",\n","        download=True,\n","        transform=TransformsSimCLR(size=args.image_size).test_transform,\n","    )\n","elif args.dataset == \"CIFAR10\":\n","    train_dataset = torchvision.datasets.CIFAR10(\n","        args.dataset_dir,\n","        train=True,\n","        download=True,\n","        transform=TransformsSimCLR(size=args.image_size).test_transform,\n","    )\n","    test_dataset = torchvision.datasets.CIFAR10(\n","        args.dataset_dir,\n","        train=False,\n","        download=True,\n","        transform=TransformsSimCLR(size=args.image_size).test_transform,\n","    )\n","else:\n","    raise NotImplementedError\n","\n","train_loader = torch.utils.data.DataLoader(\n","    train_dataset,\n","    batch_size=args.logistic_batch_size,\n","    shuffle=True,\n","    drop_last=True,\n","    num_workers=args.workers,\n",")\n","\n","test_loader = torch.utils.data.DataLoader(\n","    test_dataset,\n","    batch_size=args.logistic_batch_size,\n","    shuffle=False,\n","    drop_last=True,\n","    num_workers=args.workers,\n",")"],"execution_count":72,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"TmwXqVBH5ZX6"},"source":["### Load ResNet encoder / SimCLR and load model weights"]},{"cell_type":"code","metadata":{"id":"RTVnvx2a5QnX","colab":{"base_uri":"https://localhost:8080/","height":596},"executionInfo":{"status":"error","timestamp":1622659336738,"user_tz":240,"elapsed":988,"user":{"displayName":"Rohit Jagga","photoUrl":"","userId":"14887061695205225708"}},"outputId":"dd235190-6cc6-4477-d97c-f895fb215a76"},"source":["encoder = get_resnet(args.resnet, pretrained=False) # don't load a pre-trained model from PyTorch repo\n","n_features = encoder.fc.in_features  # get dimensions of fc layer\n","\n","# load pre-trained model from checkpoint\n","simclr_model = SimCLR(args, encoder, n_features)\n","model_fp = os.path.join(\n","    args.model_path, \"checkpoint_{}.tar\".format(args.epoch_num)\n",")\n","simclr_model.load_state_dict(torch.load(model_fp, map_location=args.device.type))\n","simclr_model = simclr_model.to(args.device)\n","    "],"execution_count":74,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-74-5dd0de1d61bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# load pre-trained model from checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msimclr_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimCLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m model_fp = os.path.join(\n\u001b[1;32m      7\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"checkpoint_{}.tar\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/SimCLR/simclr/simclr.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, encoder, projection_dim, n_features)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprojection_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         )\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, bias)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: new() received an invalid combination of arguments - got (ResNet, int), but expected one of:\n * (*, torch.device device)\n      didn't match because some of the arguments have invalid types: (!ResNet!, !int!)\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, *, torch.device device)\n * (object data, *, torch.device device)\n"]}]},{"cell_type":"code","metadata":{"id":"nl3Hfdwr-8ps","executionInfo":{"status":"ok","timestamp":1622658554882,"user_tz":240,"elapsed":5,"user":{"displayName":"Rohit Jagga","photoUrl":"","userId":"14887061695205225708"}}},"source":["# Logistic Regression Model\n","class LogisticRegression(torch.nn.Module):\n","    def __init__(self, input_size, num_classes):\n","        super(LogisticRegression, self).__init__()\n","        self.linear = nn.Linear(input_size, num_classes)\n","    \n","    def forward(self, x):\n","        out = self.linear(x)\n","        return out"],"execution_count":63,"outputs":[]},{"cell_type":"code","metadata":{"id":"HZoABGRr5Q8_","colab":{"base_uri":"https://localhost:8080/","height":215},"executionInfo":{"status":"error","timestamp":1622658557532,"user_tz":240,"elapsed":117,"user":{"displayName":"Rohit Jagga","photoUrl":"","userId":"14887061695205225708"}},"outputId":"cdf84552-0ff7-492c-94ed-aba20f032901"},"source":["## Logistic Regression\n","n_classes = 10 # stl-10 / cifar-10\n","model = LogisticRegression(simclr_model.n_features, n_classes)\n","model = model.to(args.device)"],"execution_count":64,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-64-22e6279297be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Logistic Regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;31m# stl-10 / cifar-10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimclr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'simclr_model' is not defined"]}]},{"cell_type":"code","metadata":{"id":"T694n_HQ5Tad"},"source":["optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n","criterion = torch.nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PLgDCu1uTLQ5"},"source":["### Helper functions to map all input data $X$ to their latent representations $h$ that are used in linear evaluation (they only have to be computed once)"]},{"cell_type":"code","metadata":{"id":"6B6li5NVSWR3"},"source":["def inference(loader, simclr_model, device):\n","    feature_vector = []\n","    labels_vector = []\n","    for step, (x, y) in enumerate(loader):\n","        x = x.to(device)\n","\n","        # get encoding\n","        with torch.no_grad():\n","            h, _, z, _ = simclr_model(x, x)\n","\n","        h = h.detach()\n","\n","        feature_vector.extend(h.cpu().detach().numpy())\n","        labels_vector.extend(y.numpy())\n","\n","        if step % 20 == 0:\n","            print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n","\n","    feature_vector = np.array(feature_vector)\n","    labels_vector = np.array(labels_vector)\n","    print(\"Features shape {}\".format(feature_vector.shape))\n","    return feature_vector, labels_vector\n","\n","\n","def get_features(context_model, train_loader, test_loader, device):\n","    train_X, train_y = inference(train_loader, context_model, device)\n","    test_X, test_y = inference(test_loader, context_model, device)\n","    return train_X, train_y, test_X, test_y\n","\n","\n","def create_data_loaders_from_arrays(X_train, y_train, X_test, y_test, batch_size):\n","    train = torch.utils.data.TensorDataset(\n","        torch.from_numpy(X_train), torch.from_numpy(y_train)\n","    )\n","    train_loader = torch.utils.data.DataLoader(\n","        train, batch_size=batch_size, shuffle=False\n","    )\n","\n","    test = torch.utils.data.TensorDataset(\n","        torch.from_numpy(X_test), torch.from_numpy(y_test)\n","    )\n","    test_loader = torch.utils.data.DataLoader(\n","        test, batch_size=batch_size, shuffle=False\n","    )\n","    return train_loader, test_loader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sPeoK6ZkS4MB","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1594673724500,"user_tz":-120,"elapsed":49998,"user":{"displayName":"Janne Spijkervet","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWPSVE_CLPC8ATKq76fML3p4URXO7tBSGU87FUKlI=s64","userId":"03759019175883464290"}},"outputId":"5e0306ab-d35f-4215-9ee7-93b6d691bc36"},"source":["print(\"### Creating features from pre-trained context model ###\")\n","(train_X, train_y, test_X, test_y) = get_features(\n","    simclr_model, train_loader, test_loader, args.device\n",")\n","\n","arr_train_loader, arr_test_loader = create_data_loaders_from_arrays(\n","    train_X, train_y, test_X, test_y, args.logistic_batch_size\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["### Creating features from pre-trained context model ###\n","Step [0/19]\t Computing features...\n","Features shape (4864, 2048)\n","Step [0/31]\t Computing features...\n","Step [20/31]\t Computing features...\n","Features shape (7936, 2048)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vLaebM9Qvztx","colab":{"base_uri":"https://localhost:8080/","height":884},"executionInfo":{"status":"ok","timestamp":1594673821555,"user_tz":-120,"elapsed":35023,"user":{"displayName":"Janne Spijkervet","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWPSVE_CLPC8ATKq76fML3p4URXO7tBSGU87FUKlI=s64","userId":"03759019175883464290"}},"outputId":"3ee257d4-9560-4f1b-a1bd-b72b26486891"},"source":["for epoch in range(args.logistic_epochs):\n","    loss_epoch, accuracy_epoch = train(args, arr_train_loader, simclr_model, model, criterion, optimizer)\n","    \n","    if epoch % 10 == 0:\n","      print(f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader)}\\t Accuracy: {accuracy_epoch / len(train_loader)}\")\n","\n","\n","# final testing\n","loss_epoch, accuracy_epoch = test(\n","    args, arr_test_loader, simclr_model, model, criterion, optimizer\n",")\n","print(\n","    f\"[FINAL]\\t Loss: {loss_epoch / len(test_loader)}\\t Accuracy: {accuracy_epoch / len(test_loader)}\"\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch [0/500]\t Loss: 1.2995009139964455\t Accuracy: 0.5775082236842105\n","Epoch [10/500]\t Loss: 0.5672931388804787\t Accuracy: 0.7970805921052632\n","Epoch [20/500]\t Loss: 0.5207125450435438\t Accuracy: 0.8106496710526315\n","Epoch [30/500]\t Loss: 0.4909049398020694\t Accuracy: 0.8227796052631579\n","Epoch [40/500]\t Loss: 0.4682556720156419\t Accuracy: 0.8318256578947368\n","Epoch [50/500]\t Loss: 0.44977502760134247\t Accuracy: 0.8400493421052632\n","Epoch [60/500]\t Loss: 0.4340776424658926\t Accuracy: 0.8453947368421053\n","Epoch [70/500]\t Loss: 0.42038628458976746\t Accuracy: 0.8515625\n","Epoch [80/500]\t Loss: 0.4082148718206506\t Accuracy: 0.8569078947368421\n","Epoch [90/500]\t Loss: 0.39723886471045644\t Accuracy: 0.8612253289473685\n","Epoch [100/500]\t Loss: 0.3872311193692057\t Accuracy: 0.8653371710526315\n","Epoch [110/500]\t Loss: 0.37802645877787944\t Accuracy: 0.8692434210526315\n","Epoch [120/500]\t Loss: 0.3695004205954702\t Accuracy: 0.8729440789473685\n","Epoch [130/500]\t Loss: 0.36155661313157333\t Accuracy: 0.8745888157894737\n","Epoch [140/500]\t Loss: 0.35411842088950307\t Accuracy: 0.8782894736842105\n","Epoch [150/500]\t Loss: 0.34712363073700353\t Accuracy: 0.8813733552631579\n","Epoch [160/500]\t Loss: 0.3405208807242544\t Accuracy: 0.8838404605263158\n","Epoch [170/500]\t Loss: 0.33426717551130997\t Accuracy: 0.8865131578947368\n","Epoch [180/500]\t Loss: 0.3283261609704871\t Accuracy: 0.8887746710526315\n","Epoch [190/500]\t Loss: 0.3226670042464608\t Accuracy: 0.8908305921052632\n","Epoch [200/500]\t Loss: 0.31726320636899846\t Accuracy: 0.8930921052631579\n","Epoch [210/500]\t Loss: 0.31209210973036916\t Accuracy: 0.8955592105263158\n","Epoch [220/500]\t Loss: 0.30713410283389847\t Accuracy: 0.899671052631579\n","Epoch [230/500]\t Loss: 0.30237222188397456\t Accuracy: 0.9017269736842105\n","Epoch [240/500]\t Loss: 0.29779163944093806\t Accuracy: 0.9033717105263158\n","Epoch [250/500]\t Loss: 0.2933794495306517\t Accuracy: 0.9046052631578947\n","Epoch [260/500]\t Loss: 0.2891242833513963\t Accuracy: 0.9060444078947368\n","Epoch [270/500]\t Loss: 0.28501601752481964\t Accuracy: 0.9078947368421053\n","Epoch [280/500]\t Loss: 0.28104570664857564\t Accuracy: 0.9091282894736842\n","Epoch [290/500]\t Loss: 0.2772053848755987\t Accuracy: 0.9115953947368421\n","Epoch [300/500]\t Loss: 0.2734877474998173\t Accuracy: 0.9132401315789473\n","Epoch [310/500]\t Loss: 0.26988626153845535\t Accuracy: 0.9142680921052632\n","Epoch [320/500]\t Loss: 0.26639497829111\t Accuracy: 0.9161184210526315\n","Epoch [330/500]\t Loss: 0.2630084604024887\t Accuracy: 0.9165296052631579\n","Epoch [340/500]\t Loss: 0.2597217277476662\t Accuracy: 0.916735197368421\n","Epoch [350/500]\t Loss: 0.25653022135558884\t Accuracy: 0.9177631578947368\n","Epoch [360/500]\t Loss: 0.2534297492943312\t Accuracy: 0.9189967105263158\n","Epoch [370/500]\t Loss: 0.2504164976508994\t Accuracy: 0.920641447368421\n","Epoch [380/500]\t Loss: 0.24748698269066058\t Accuracy: 0.9216694078947368\n","Epoch [390/500]\t Loss: 0.24463806026860288\t Accuracy: 0.9226973684210527\n","Epoch [400/500]\t Loss: 0.2418668740674069\t Accuracy: 0.9239309210526315\n","Epoch [410/500]\t Loss: 0.23917087206715032\t Accuracy: 0.924547697368421\n","Epoch [420/500]\t Loss: 0.23654781987792567\t Accuracy: 0.9249588815789473\n","Epoch [430/500]\t Loss: 0.2339957356452942\t Accuracy: 0.92578125\n","Epoch [440/500]\t Loss: 0.23151302729782305\t Accuracy: 0.9266036184210527\n","Epoch [450/500]\t Loss: 0.2290983082432496\t Accuracy: 0.9280427631578947\n","Epoch [460/500]\t Loss: 0.22675060912182457\t Accuracy: 0.9286595394736842\n","Epoch [470/500]\t Loss: 0.22446929545778976\t Accuracy: 0.9290707236842105\n","Epoch [480/500]\t Loss: 0.22225411863703476\t Accuracy: 0.9296875\n","Epoch [490/500]\t Loss: 0.22010527002184013\t Accuracy: 0.9311266447368421\n","[FINAL]\t Loss: 0.5600880749763981\t Accuracy: 0.8188004032258065\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dxK5MuRbR7tW"},"source":[""],"execution_count":null,"outputs":[]}]}